import time
import math
from evaluation import evaluate_board, get_game_phase, is_passed_pawn
from constants import piece_score


class Search:
    def __init__(self, ai_turn):
        self.ai_turn = "w" if ai_turn == 0 else "b"
        self.best_move = None
        self.total_nodes = 0
        self.total_branch_cutoff = 0
        self.total_nodes_leaf = 0
        self.execution_time = 0
        self.time_generate_moves = 0
        self.is_endgame = False
        self.DEPTH = 4
        self.algo_search = "Alpha Beta"

    def reset_parameters(self):
        self.best_move = None
        self.total_nodes = 0
        self.total_branch_cutoff = 0
        self.total_nodes_leaf = 0
        self.time_generate_moves = 0

    def get_best_move(self, gs, use_minimax=False):
        self.reset_parameters()
        start_time = time.time()
        self.is_endgame = get_game_phase(gs)
        if use_minimax:
            self.algo_search = "Minimax"
            self.max_score = self.__minimax(gs, self.DEPTH, True)
        else:
            self.algo_search = "Alpha Beta"
            alpha = -math.inf
            beta = math.inf
            self.max_score = self.__alpha_beta_pruning(gs, self.DEPTH, alpha, beta, True)
        self.execution_time = time.time() - start_time
        return self.best_move

    def __sort_moves(self, gs, moves):
        def move_score(move):
            score = 0
            material_diff = evaluate_board(gs, self.ai_turn, self.is_endgame)
            is_winning = (self.ai_turn == "b" and material_diff > 500) or (self.ai_turn == "w" and material_diff < -500)

            # Prioritize checkmate above all else
            gs.makeMove(move)
            if gs.inCheck:
                opp_color = "w" if self.ai_turn == "b" else "b"
                temp_turn = gs.turn
                gs.turn = opp_color
                legal_moves = gs.getValidMoves()
                gs.turn = temp_turn
                if not legal_moves:  # Checkmate
                    gs.undoMove()
                    return 99999999  # Return immediately to prioritize checkmate

            # Other scoring criteria only if not checkmate
            if self.is_endgame:
                if gs.inCheck:
                    opp_king = gs.kingLocation[opp_color]
                    if opp_king[0] in (0, 7) or opp_king[1] in (0, 7):
                        score += 1200
                    else:
                        score += 1000
                if move.movePiece[1] == "p":
                    end_row, end_col = move.sqEnd
                    if is_passed_pawn(gs, end_row, end_col, move.movePiece[0]):
                        rank = end_row if move.movePiece[0] == "b" else (7 - end_row)
                        score += 100 + rank * 20
                    else:
                        score += 50
                if move.movePiece[1] == "K":
                    end_row, end_col = move.sqEnd
                    if (2 <= end_row <= 5) and (2 <= end_col <= 5):
                        score += 80
                    if is_winning:
                        opp_king = gs.kingLocation["w" if self.ai_turn == "b" else "b"]
                        dist_before = abs(gs.kingLocation[self.ai_turn][0] - opp_king[0]) + \
                                      abs(gs.kingLocation[self.ai_turn][1] - opp_king[1])
                        dist_after = abs(end_row - opp_king[0]) + abs(end_col - opp_king[1])
                        if dist_after < dist_before:
                            score += 100
            gs.undoMove()
            if move.capturedPiece != "--":
                captured_value = piece_score[move.capturedPiece[1]]
                score += captured_value
            if move.movePiece[1] in ["N", "B"]:
                score += 50
            return score

        return sorted(moves, key=move_score, reverse=True)

    def __quiescence_search(self, gs, alpha, beta, maximizing_player):
        self.total_nodes_leaf += 1
        eval_score = evaluate_board(gs, self.ai_turn, self.is_endgame)

        if maximizing_player:
            if eval_score >= beta:
                return beta
            alpha = max(alpha, eval_score)
        else:
            if eval_score <= alpha:
                return alpha
            beta = min(beta, eval_score)

        capture_moves = [move for move in gs.getValidMoves() if move.capturedPiece != "--"]
        if not capture_moves:
            return eval_score

        capture_moves = self.__sort_moves(gs, capture_moves)

        if maximizing_player:
            for move in capture_moves:
                gs.makeMove(move)
                self.total_nodes += 1
                score = self.__quiescence_search(gs, alpha, beta, False)
                gs.undoMove()
                if score >= beta:
                    self.total_branch_cutoff += 1
                    return beta
                alpha = max(alpha, score)
            return alpha
        else:
            for move in capture_moves:
                gs.makeMove(move)
                self.total_nodes += 1
                score = self.__quiescence_search(gs, alpha, beta, True)
                gs.undoMove()
                if score <= alpha:
                    self.total_branch_cutoff += 1
                    return alpha
                beta = min(beta, score)
            return beta

    def __minimax(self, gs, depth, maximizing_player):
        if depth == 0 or len(gs.getValidMoves()) == 0:
            self.total_nodes_leaf += 1
            return evaluate_board(gs, self.ai_turn, self.is_endgame)

        moves = self.__sort_moves(gs, gs.getValidMoves())
        if maximizing_player:
            max_eval = -math.inf
            for move in moves:
                gs.makeMove(move)
                self.total_nodes += 1
                eval_score = self.__minimax(gs, depth - 1, False)
                gs.undoMove()
                if eval_score > max_eval:
                    max_eval = eval_score
                    if depth == self.DEPTH:
                        self.best_move = move
            return max_eval
        else:
            min_eval = math.inf
            for move in moves:
                gs.makeMove(move)
                self.total_nodes += 1
                eval_score = self.__minimax(gs, depth - 1, True)
                gs.undoMove()
                if eval_score < min_eval:
                    min_eval = eval_score
                    if depth == self.DEPTH:
                        self.best_move = move
            return min_eval

    def __alpha_beta_pruning(self, gs, depth, alpha, beta, maximizing_player):
        if depth == 0 or len(gs.getValidMoves()) == 0:
            return self.__quiescence_search(gs, alpha, beta, maximizing_player)

        start = time.time()
        moves = self.__sort_moves(gs, gs.getValidMoves())
        self.time_generate_moves += time.time() - start

        if maximizing_player:
            max_eval = -math.inf
            for move in moves:
                gs.makeMove(move)
                self.total_nodes += 1
                eval_score = self.__alpha_beta_pruning(gs, depth - 1, alpha, beta, False)
                gs.undoMove()
                if eval_score > max_eval:
                    max_eval = eval_score
                    if depth == self.DEPTH:
                        self.best_move = move
                alpha = max(alpha, eval_score)
                if beta <= alpha:
                    self.total_branch_cutoff += 1
                    break
            return max_eval
        else:
            min_eval = math.inf
            for move in moves:
                gs.makeMove(move)
                self.total_nodes += 1
                eval_score = self.__alpha_beta_pruning(gs, depth - 1, alpha, beta, True)
                gs.undoMove()
                if eval_score < min_eval:
                    min_eval = eval_score
                    if depth == self.DEPTH:
                        self.best_move = move
                beta = min(beta, eval_score)
                if beta <= alpha:
                    self.total_branch_cutoff += 1
                    break
            return min_eval